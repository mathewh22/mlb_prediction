{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLB Predictor Project\n",
    "\n",
    "Group 21, Plotters for Success\n",
    "\n",
    "Gerardo Skrut, Victor Gikunda, Mathew Huang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "import csv\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to importing the data, we cleaned and explored the existing data.\n",
    "\n",
    "Finally, After we consolidated two datasets with pitching and batting, we are going to separate each portion to inputs and outputs respectively. \n",
    "\n",
    "Our inputs overall would include Left Field, Right Field, and Centerfield Distance, Maximum and minimum wall height, Day/night, Attendance, Precipitation, Sky Condition, Temperature, Wind Direction, and Wind Speed. \n",
    "\n",
    "For Pitching specifically, we will be using the pitcher's **Season ERA** from the 2023 Season. \n",
    "\n",
    "For Batting Specifically, we will be using the batter's **Season Batting Average** from the 2023 Season.\n",
    "\n",
    "Our outputs would be game specific statistics. \n",
    "\n",
    "For Pitching, we would have the number of Hits Allowed, Runs Allowed, Earned Runs, Walks Given, Hit by Pitches, and Wild Pitches.\n",
    "\n",
    "For Batting, we would have the number of Hits, Doubles, Triples, Home Runs, RBIs, Walks, and Strikeouts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ballpark Dataset Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Column Values:\n",
      "left_field         331.833333\n",
      "center_field       404.166667\n",
      "right_field        328.333333\n",
      "min_wall_height      7.553333\n",
      "max_wall_height     14.266667\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load ballparks data\n",
    "data = pd.read_csv('ballparks.csv')\n",
    "\n",
    "# Filter for relevant columns\n",
    "columns_to_keep = ['team_name', 'ballpark', 'left_field', 'center_field', 'right_field', 'min_wall_height', 'max_wall_height']\n",
    "data_filtered = data[columns_to_keep]\n",
    "\n",
    "# Calculate average for numeric columns\n",
    "average_values = data_filtered[['left_field', 'center_field', 'right_field', 'min_wall_height', 'max_wall_height']].mean()\n",
    "\n",
    "# Print the average values\n",
    "print(\"Average Column Values:\")\n",
    "print(average_values)\n",
    "\n",
    "# Save the filtered data\n",
    "data_filtered.to_csv('2023_filtered_ballpark_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game Information Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Values for Numeric Columns:\n",
      "attendance    29356.347087\n",
      "temp             72.413835\n",
      "windspeed         6.466828\n",
      "dtype: float64\n",
      "\n",
      "Most Frequent Values for Categorical Columns:\n",
      "daynight      night\n",
      "precip         none\n",
      "sky          cloudy\n",
      "winddir     unknown\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load game info data\n",
    "data = pd.read_csv('2023gameinfo.csv')\n",
    "\n",
    "# Filter for relevant columns\n",
    "columns_to_keep = ['gid', 'daynight', 'attendance', 'precip', 'sky', 'temp', 'winddir', 'windspeed']\n",
    "data_filtered = data[columns_to_keep]\n",
    "\n",
    "# Calculate average for numeric columns\n",
    "numeric_columns = ['attendance', 'temp', 'windspeed']\n",
    "average_values = data_filtered[numeric_columns].mean()\n",
    "\n",
    "# Find the most frequent value for categorical columns\n",
    "categorical_columns = ['daynight', 'precip', 'sky', 'winddir']\n",
    "most_frequent_values = data_filtered[categorical_columns].mode().iloc[0]\n",
    "\n",
    "# Print results\n",
    "print(\"Average Values for Numeric Columns:\")\n",
    "print(average_values)\n",
    "print(\"\\nMost Frequent Values for Categorical Columns:\")\n",
    "print(most_frequent_values)\n",
    "\n",
    "# Save filtered data\n",
    "data_filtered.to_csv('2023_filtered_gameinfo_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batting Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''filters for relevant batting player data'''\n",
    "# load csv file\n",
    "data = pd.read_csv('2023batting.csv')\n",
    "\n",
    "# filters for columns with relevant data\n",
    "columns_to_keep = ['gid', 'id', 'team', 'b_ab', 'b_h', 'b_d', 'b_t', 'b_hr', 'b_rbi', 'b_w', 'b_k', 'date', 'wl']  \n",
    "\n",
    "# creates a new data frame\n",
    "data_filtered = data[columns_to_keep]\n",
    "\n",
    "# save new csv file\n",
    "data_filtered.to_csv('2023_filtered_batting_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Dataset includes batting data for players who do not bat, this filters out those players who had zero at bats (i.e. pitchers)'''\n",
    "\n",
    "updated_rows = []\n",
    "with open('2023_filtered_batting_data.csv', 'r') as data_file:  \n",
    "    data_reader = csv.reader(data_file)\n",
    "    header = next(data_reader)  \n",
    "    updated_rows.append(header)\n",
    "\n",
    "    # reads each row\n",
    "    for row in data_reader:\n",
    "        # checks if players number of plate appearances is zero\n",
    "        if int(row[3]) == 0:\n",
    "            # skips if plate appearance is equal to zero  \n",
    "            continue  \n",
    "\n",
    "        # appends data if not    \n",
    "        updated_rows.append(row)\n",
    "\n",
    "# creates a new csv file with updated data\n",
    "with open('2023_batting_data_cleaned.csv', 'w', newline='') as updated_file:\n",
    "    writer = csv.writer(updated_file)\n",
    "    writer.writerows(updated_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Merges relevant data into a one csv file'''\n",
    "\n",
    "# loads ball park data into a dictionary\n",
    "stadium_data = {}\n",
    "with open('2023_filtered_ballpark_data.csv', 'r') as stadium_file:  \n",
    "    stadium_reader = csv.DictReader(stadium_file)\n",
    "    for row in stadium_reader:\n",
    "        # uses the team name as the key for each entry\n",
    "        team_name = row['team_name']  \n",
    "        # stores the data for the corresponding team\n",
    "        stadium_data[team_name] = row  \n",
    "\n",
    "# loads game info data into a dictionary       \n",
    "gameinfo_data = {}\n",
    "with open('2023_filtered_gameinfo_data.csv', 'r') as gameinfo_file:  \n",
    "    gameinfo_reader = csv.DictReader(gameinfo_file)\n",
    "    for row in gameinfo_reader:\n",
    "        # uses the game id as the key for each entry\n",
    "        gid = row['gid']  \n",
    "        # stores the data for the corresponding game id \n",
    "        gameinfo_data[gid] = row  \n",
    "        \n",
    "\n",
    "# read batting data, merge with ball park data, store updated rows\n",
    "updated_rows = []\n",
    "with open('2023_batting_data_cleaned.csv', 'r') as game_log_file: \n",
    "    batting_log = csv.reader(game_log_file)\n",
    "    # captures the header row\n",
    "    header = next(batting_log)\n",
    "\n",
    "    # extracts column names of the ball park data\n",
    "    stadium_columns = list(stadium_data.values())[0].keys() \n",
    "    # extracts column names of the game info data, excluding 'gid' since it already exist in the dataset \n",
    "    gameinfo_columns = list(gameinfo_data.values())[0].keys()\n",
    "    new_gameinfo_columns = []\n",
    "    \n",
    "    for col in gameinfo_columns:\n",
    "        if col != 'gid':\n",
    "            new_gameinfo_columns.append(col)\n",
    "\n",
    "    # appens the original header with additional stadium and game info columns           \n",
    "    updated_rows.append(header + list(stadium_columns) + new_gameinfo_columns)          \n",
    "\n",
    "    # iterates through each row of the batting log data      \n",
    "    for row in batting_log:\n",
    "        \n",
    "        # extracts game id\n",
    "        gid = row[0] \n",
    "        # extracts first three letters of the game id, which is the team id\n",
    "        team_id = gid[:3]\n",
    "\n",
    "        # checks if the team id exists in the stadium data        \n",
    "        if team_id in stadium_data:\n",
    "            # retieves ball park data for that team and appends it to the row\n",
    "            # this can be done because the first three characters of the game id represent the team id of the home team \n",
    "            stadium_info = stadium_data[team_id]\n",
    "            row.extend(stadium_info.values())\n",
    "        \n",
    "        # checks if game id is in the game info data\n",
    "        if gid in gameinfo_data:\n",
    "            \n",
    "            # retrieves game info data to corresponding game id\n",
    "            gameinfo = gameinfo_data[gid]\n",
    "            updated_gameinfo = []\n",
    "            # removes the duplicate game id column and appends the other values\n",
    "            for key, value in gameinfo.items():\n",
    "                if key != 'gid':\n",
    "                    updated_gameinfo.append(value)\n",
    "            \n",
    "            # adds game info data to current row\n",
    "            row.extend(updated_gameinfo)\n",
    "\n",
    "        # adds new data to row   \n",
    "        updated_rows.append(row)\n",
    "\n",
    "\n",
    "# new csv file output with updated data\n",
    "with open('2023_merged_batting_data.csv', 'w', newline='') as updated_file:\n",
    "    writer = csv.writer(updated_file)\n",
    "    writer.writerows(updated_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Batting Average: 0.226\n"
     ]
    }
   ],
   "source": [
    "'''adds a row with calculated season average for each player since the data set only includes specific game log data'''\n",
    " \n",
    "# Dictionary to store season totals\n",
    "season_avg_data = {}\n",
    "\n",
    "# Process input file to calculate season totals for each player\n",
    "with open('2023_merged_batting_data.csv', 'r') as stat_file:\n",
    "    stat_reader = csv.DictReader(stat_file)\n",
    "    header = stat_reader.fieldnames + ['season_batting_avg']\n",
    "\n",
    "    for row in stat_reader:\n",
    "        name = row['id']\n",
    "        bats = int(row['b_ab'])\n",
    "        hits = int(row['b_h'])\n",
    "\n",
    "        # Update season totals for the player\n",
    "        if name in season_avg_data:\n",
    "            season_avg_data[name]['total_at_bats'] += bats\n",
    "            season_avg_data[name]['total_hits'] += hits\n",
    "        else:\n",
    "            season_avg_data[name] = {'total_at_bats': bats, 'total_hits': hits}\n",
    "\n",
    "# Prepare updated rows with calculated season batting averages\n",
    "updated_rows = []\n",
    "with open('2023_merged_batting_data.csv', 'r') as stat_file:\n",
    "    stat_reader = csv.DictReader(stat_file)\n",
    "    for row in stat_reader:\n",
    "        name = row['id']\n",
    "        total_bats = season_avg_data[name]['total_at_bats']\n",
    "        total_hits = season_avg_data[name]['total_hits']\n",
    "\n",
    "        # Calculate player's season batting average\n",
    "        batting_average = total_hits / total_bats\n",
    "        row['season_batting_avg'] = f\"{batting_average:.3f}\"\n",
    "\n",
    "        updated_rows.append(row)\n",
    "\n",
    "# Write updated data to a new CSV file\n",
    "with open('2023_complete_batting_data.csv', 'w', newline='') as updated_file:\n",
    "    writer = csv.DictWriter(updated_file, fieldnames=header)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(updated_rows)\n",
    "\n",
    "# Calculate overall average batting average (NEW ADDITION)\n",
    "batting_averages = [\n",
    "    stats['total_hits'] / stats['total_at_bats']\n",
    "    for stats in season_avg_data.values()\n",
    "    if stats['total_at_bats'] > 0  # Avoid division by zero\n",
    "]\n",
    "\n",
    "average_batting_avg = sum(batting_averages) / len(batting_averages) if batting_averages else 0\n",
    "\n",
    "# Print the overall average batting average (does not affect functionality)\n",
    "print(f\"Average Batting Average: {average_batting_avg:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''formats finalzied dataset properly'''\n",
    "\n",
    "# creates a mapping of player IDs to their full names\n",
    "name_id_map = {}\n",
    "with open('2023allplayers.csv', 'r') as name_file:  \n",
    "    name_reader = csv.DictReader(name_file)\n",
    "    for row in name_reader:\n",
    "        # combines first and last name columns to form the full name and maps it respectively \n",
    "        name_id_map[row['id']] = f\"{row['first']} {row['last']}\"\n",
    "\n",
    "# reads the baseball data file and replace IDs with full names\n",
    "updated_rows = []\n",
    "with open('2023_complete_batting_data.csv', 'r') as data_file: \n",
    "    data_reader = csv.reader(data_file)\n",
    "    header = next(data_reader)  \n",
    "    updated_rows.append(header)\n",
    "\n",
    "    # iterates through each row of the data\n",
    "    for row in data_reader:\n",
    "        \n",
    "        # converts the date format from 'YYYYMMDD' to 'MM/DD/YYYY'\n",
    "        date_str = row[11]\n",
    "        date_format = datetime.strptime(date_str, '%Y%m%d').strftime('%m/%d/%Y')\n",
    "        row[11] = date_format\n",
    "        \n",
    "        # replaces the player id with the player's full name\n",
    "        player_id = row[1] \n",
    "        if player_id in name_id_map:\n",
    "            row[1] = name_id_map[player_id] \n",
    "\n",
    "        # adds the updated row\n",
    "        updated_rows.append(row)\n",
    "\n",
    "# writes the updated csv file with all data and cleaned\n",
    "with open('2023_full_batting_stats_cleaned.csv', 'w', newline='') as updated_file:\n",
    "    writer = csv.writer(updated_file)\n",
    "    writer.writerows(updated_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            gid                 id team  b_ab  b_h  b_d  b_t  b_hr  b_rbi  \\\n",
      "0  BOS202303300     Cedric Mullins  BAL     4    1    0    0     0      1   \n",
      "1  BOS202303300    Adley Rutschman  BAL     5    5    0    0     1      4   \n",
      "2  BOS202303300  Anthony Santander  BAL     6    2    1    0     0      0   \n",
      "3  BOS202303300   Ryan Mountcastle  BAL     4    1    1    0     0      1   \n",
      "4  BOS202303300   Gunnar Henderson  BAL     3    0    0    0     0      0   \n",
      "\n",
      "   b_w  b_k        date wl team_name     ballpark left_field center_field  \\\n",
      "0    2    1  03/30/2023  w       BOS  Fenway Park        310          420   \n",
      "1    1    0  03/30/2023  w       BOS  Fenway Park        310          420   \n",
      "2    0    2  03/30/2023  w       BOS  Fenway Park        310          420   \n",
      "3    2    0  03/30/2023  w       BOS  Fenway Park        310          420   \n",
      "4    2    2  03/30/2023  w       BOS  Fenway Park        310          420   \n",
      "\n",
      "   right_field min_wall_height  max_wall_height daynight  attendance precip  \\\n",
      "0          302             3.0               37      day     36049.0   none   \n",
      "1          302             3.0               37      day     36049.0   none   \n",
      "2          302             3.0               37      day     36049.0   none   \n",
      "3          302             3.0               37      day     36049.0   none   \n",
      "4          302             3.0               37      day     36049.0   none   \n",
      "\n",
      "     sky  temp winddir  windspeed  season_batting_avg  \n",
      "0  sunny  38.0    ltor       12.0               0.226  \n",
      "1  sunny  38.0    ltor       12.0               0.273  \n",
      "2  sunny  38.0    ltor       12.0               0.257  \n",
      "3  sunny  38.0    ltor       12.0               0.267  \n",
      "4  sunny  38.0    ltor       12.0               0.260  \n"
     ]
    }
   ],
   "source": [
    "final_csv = '2023_full_batting_stats_cleaned.csv'\n",
    "\n",
    "data = pd.read_csv(final_csv, low_memory = False)\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pitching Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''filters for relevant player pitching data'''\n",
    "# load csv file\n",
    "data = pd.read_csv('2023pitching.csv')\n",
    "\n",
    "# filters for columns with relevant data\n",
    "columns_to_keep = ['gid', 'id', 'team', 'p_ipouts', 'p_seq', 'p_h', 'p_r', 'p_er', 'p_w','p_k', 'p_hbp', 'p_wp', 'date', 'wl']  \n",
    "\n",
    "# creates a new data frame\n",
    "data_filtered = data[columns_to_keep]\n",
    "\n",
    "# save new csv file\n",
    "data_filtered.to_csv('2023_filtered_pitching_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''merges pitcher game log data with ball park and game info data'''\n",
    "\n",
    "# load ball park data into a dictionary\n",
    "stadium_data = {}\n",
    "with open('2023_filtered_ballpark_data.csv', 'r') as stadium_file:  \n",
    "    stadium_reader = csv.DictReader(stadium_file)\n",
    "    for row in stadium_reader:\n",
    "        # extracts the team name column\n",
    "        team_name = row['team_name'] \n",
    "        # uses team name as a key and the row as the value \n",
    "        stadium_data[team_name] = row  \n",
    "\n",
    "# loads game info data into a dictionary        \n",
    "gameinfo_data = {}\n",
    "with open('2023_filtered_gameinfo_data.csv', 'r') as gameinfo_file:  \n",
    "    gameinfo_reader = csv.DictReader(gameinfo_file)\n",
    "    for row in gameinfo_reader:\n",
    "        # extracts the 'gid' column\n",
    "        gid = row['gid']  \n",
    "        # uses the game id as a key and the row as the value\n",
    "        gameinfo_data[gid] = row  \n",
    "        \n",
    "\n",
    "# read pitching data, merge with ball park data, store updated rows\n",
    "updated_rows = []\n",
    "with open('2023_filtered_pitching_data.csv', 'r') as game_log_file: \n",
    "    pitching_log = csv.reader(game_log_file)\n",
    "    # captures the header row\n",
    "    header = next(pitching_log)  \n",
    "\n",
    "\n",
    "    # extarcts column names of ball park data\n",
    "    stadium_columns = list(stadium_data.values())[0].keys()  \n",
    "    # extracts column names of the game info data, excluding 'gid' since it already exist in the dataset\n",
    "    gameinfo_columns = list(gameinfo_data.values())[0].keys()\n",
    "    new_gameinfo_columns = []\n",
    "    \n",
    "    for col in gameinfo_columns:\n",
    "        if col != 'gid':\n",
    "            new_gameinfo_columns.append(col)\n",
    "\n",
    "    # appends the original header with additional stadium and game info columns           \n",
    "    updated_rows.append(header + list(stadium_columns) + new_gameinfo_columns)\n",
    "\n",
    "\n",
    "    # interates through each row of the pitching log data\n",
    "    for row in pitching_log:\n",
    "        # extracts the game id\n",
    "        gid = row[0]  \n",
    "        # extracts the first three letter of the game id, which is the team id\n",
    "        team_id = gid[:3] \n",
    "\n",
    "        # checks if the team id exists in the staidum data \n",
    "        if team_id in stadium_data:\n",
    "            \n",
    "            # retrieves he ball park data for that team and appends it to the row\n",
    "            # this can be done because the first three character of the game id represent the team if of the home team\n",
    "            stadium_info = stadium_data[team_id]\n",
    "            row.extend(stadium_info.values())\n",
    "        \n",
    "        # checks if the game id is in the game info data \n",
    "        if gid in gameinfo_data:\n",
    "            \n",
    "            # retrieves game info data to corresponding game id \n",
    "            gameinfo = gameinfo_data[gid]\n",
    "            updated_gameinfo = []\n",
    "            # removes the duplicate game id column and appends the other values\n",
    "            for key, value in gameinfo.items():\n",
    "                if key != 'gid':\n",
    "                    updated_gameinfo.append(value)\n",
    "\n",
    "            # adds game info data to current row\n",
    "            row.extend(updated_gameinfo)\n",
    "\n",
    "        # adds new data to row   \n",
    "        updated_rows.append(row)\n",
    "\n",
    "\n",
    "# new csv file output with updated data\n",
    "with open('2023_merged_pitching_data.csv', 'w', newline='') as updated_file:\n",
    "    writer = csv.writer(updated_file)\n",
    "    writer.writerows(updated_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Season ERA: 5.870\n"
     ]
    }
   ],
   "source": [
    "'''calculates the season ERA for each pitcher and merge the dataset'''\n",
    "import csv\n",
    "\n",
    "# Initialize dictionary to store season totals\n",
    "season_avg_data = {}\n",
    "\n",
    "# Process input file to calculate season ERA totals for each pitcher\n",
    "with open('2023_merged_pitching_data.csv', 'r') as stat_file:\n",
    "    stat_reader = csv.DictReader(stat_file)\n",
    "    header = stat_reader.fieldnames + ['season_era']\n",
    "\n",
    "    for row in stat_reader:\n",
    "        name = row['id']\n",
    "        outs = int(row['p_ipouts'])\n",
    "        earned_runs = int(row['p_er'])\n",
    "\n",
    "        # Update season totals for the pitcher\n",
    "        if name in season_avg_data:\n",
    "            season_avg_data[name]['total_innings'] += (outs / 3)\n",
    "            season_avg_data[name]['total_earned_runs'] += earned_runs\n",
    "        else:\n",
    "            season_avg_data[name] = {'total_innings': (outs / 3), 'total_earned_runs': earned_runs}\n",
    "\n",
    "# Prepare updated rows with calculated season ERA\n",
    "updated_rows = []\n",
    "with open('2023_merged_pitching_data.csv', 'r') as stat_file:\n",
    "    stat_reader = csv.DictReader(stat_file)\n",
    "    for row in stat_reader:\n",
    "        name = row['id']\n",
    "        innings = season_avg_data[name]['total_innings']\n",
    "        earned_runs = season_avg_data[name]['total_earned_runs']\n",
    "\n",
    "        # Calculate season ERA\n",
    "        season_era = 9 * (earned_runs / innings)\n",
    "        row['season_era'] = f\"{season_era:.3f}\"\n",
    "\n",
    "        updated_rows.append(row)\n",
    "\n",
    "# Write updated data to a new CSV file\n",
    "with open('2023_complete_pitching_data.csv', 'w', newline='') as updated_file:\n",
    "    writer = csv.DictWriter(updated_file, fieldnames=header)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(updated_rows)\n",
    "\n",
    "# Calculate overall average season ERA (NEW ADDITION)\n",
    "season_eras = [\n",
    "    9 * (stats['total_earned_runs'] / stats['total_innings'])\n",
    "    for stats in season_avg_data.values()\n",
    "    if stats['total_innings'] > 0  # Avoid division by zero\n",
    "]\n",
    "\n",
    "average_season_era = sum(season_eras) / len(season_eras) if season_eras else 0\n",
    "\n",
    "# Print the overall average season ERA (does not affect functionality)\n",
    "print(f\"Average Season ERA: {average_season_era:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the dataset: ['gid', 'id', 'team', 'p_ipouts', 'p_seq', 'p_h', 'p_r', 'p_er', 'p_w', 'p_k', 'p_hbp', 'p_wp', 'date', 'wl', 'team_name', 'ballpark', 'left_field', 'center_field', 'right_field', 'min_wall_height', 'max_wall_height', 'daynight', 'attendance', 'precip', 'sky', 'temp', 'winddir', 'windspeed', 'season_era']\n",
      "Date column detected at index 12 based on column name.\n",
      "Data cleaning complete. Updated dataset saved.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# Load the first row (header) to see the column names\n",
    "with open('2023_complete_pitching_data.csv', 'r') as data_file:\n",
    "    data_reader = csv.reader(data_file)\n",
    "    header = next(data_reader)\n",
    "    print(\"Columns in the dataset:\", header)\n",
    "\n",
    "# Automatically detect date column by checking column names or data format\n",
    "date_column_index = None\n",
    "\n",
    "# Detect column with YYYYMMDD pattern or name containing \"date\"\n",
    "for i, column in enumerate(header):\n",
    "    if \"date\" in column.lower():  # Name-based detection\n",
    "        date_column_index = i\n",
    "        print(f\"Date column detected at index {date_column_index} based on column name.\")\n",
    "        break\n",
    "\n",
    "if date_column_index is None:\n",
    "    # Fallback to detecting by data format in the first row\n",
    "    for i, row in enumerate(data_reader):\n",
    "        for col_index, value in enumerate(row):\n",
    "            try:\n",
    "                if len(value) == 8:  # Typical YYYYMMDD format length\n",
    "                    datetime.strptime(value, '%Y%m%d')\n",
    "                    date_column_index = col_index\n",
    "                    print(f\"Date column detected at index {date_column_index} based on data format.\")\n",
    "                    break\n",
    "            except ValueError:\n",
    "                continue\n",
    "        if date_column_index is not None:\n",
    "            break\n",
    "\n",
    "# Update rows with automatic date detection\n",
    "name_id_map = {}\n",
    "with open('2023allplayers.csv', 'r') as name_file:  \n",
    "    name_reader = csv.DictReader(name_file)\n",
    "    for row in name_reader:\n",
    "        name_id_map[row['id']] = f\"{row['first']} {row['last']}\"\n",
    "\n",
    "updated_rows = []\n",
    "\n",
    "with open('2023_complete_pitching_data.csv', 'r') as data_file: \n",
    "    data_reader = csv.reader(data_file)\n",
    "    header = next(data_reader)\n",
    "    updated_rows.append(header)\n",
    "\n",
    "    for row in data_reader:\n",
    "        if date_column_index is not None:\n",
    "            # Convert detected date column format\n",
    "            try:\n",
    "                date_str = row[date_column_index]\n",
    "                date_format = datetime.strptime(date_str, '%Y%m%d').strftime('%m/%d/%Y')\n",
    "                row[date_column_index] = date_format\n",
    "            except ValueError:\n",
    "                pass  # Handle rows where the date might not conform\n",
    "\n",
    "        # Replace player ID with name\n",
    "        player_id = row[1]\n",
    "        if player_id in name_id_map:\n",
    "            row[1] = name_id_map[player_id]\n",
    "\n",
    "        updated_rows.append(row)\n",
    "\n",
    "# Write cleaned data\n",
    "with open('2023_full_pitching_stats_cleaned.csv', 'w', newline='') as updated_file:\n",
    "    writer = csv.writer(updated_file)\n",
    "    writer.writerows(updated_rows)\n",
    "\n",
    "print(\"Data cleaning complete. Updated dataset saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pitching Data Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            gid               id team  p_ipouts  p_seq  p_h  p_r  p_er  p_w  \\\n",
      "0  BOS202303300      Kyle Gibson  BAL        15      1    6    4     4    1   \n",
      "1  BOS202303300      Keegan Akin  BAL         3      2    1    0     0    0   \n",
      "2  BOS202303300     Cionel Perez  BAL         3      3    0    0     0    0   \n",
      "3  BOS202303300      Bryan Baker  BAL         2      4    2    3     3    1   \n",
      "4  BOS202303300  Logan Gillaspie  BAL         1      5    0    0     0    0   \n",
      "\n",
      "   p_k  p_hbp  p_wp        date wl team_name     ballpark left_field  \\\n",
      "0    3      1     0  03/30/2023  w       BOS  Fenway Park        310   \n",
      "1    2      0     0  03/30/2023  w       BOS  Fenway Park        310   \n",
      "2    0      0     0  03/30/2023  w       BOS  Fenway Park        310   \n",
      "3    1      1     0  03/30/2023  w       BOS  Fenway Park        310   \n",
      "4    1      0     0  03/30/2023  w       BOS  Fenway Park        310   \n",
      "\n",
      "  center_field  right_field min_wall_height  max_wall_height daynight  \\\n",
      "0          420          302             3.0               37      day   \n",
      "1          420          302             3.0               37      day   \n",
      "2          420          302             3.0               37      day   \n",
      "3          420          302             3.0               37      day   \n",
      "4          420          302             3.0               37      day   \n",
      "\n",
      "   attendance precip    sky  temp winddir  windspeed  season_era  \n",
      "0     36049.0   none  sunny  38.0    ltor       12.0       4.708  \n",
      "1     36049.0   none  sunny  38.0    ltor       12.0       6.845  \n",
      "2     36049.0   none  sunny  38.0    ltor       12.0       3.436  \n",
      "3     36049.0   none  sunny  38.0    ltor       12.0       4.169  \n",
      "4     36049.0   none  sunny  38.0    ltor       12.0       6.000  \n"
     ]
    }
   ],
   "source": [
    "final_csv = '2023_full_pitching_stats_cleaned.csv'\n",
    "\n",
    "data = pd.read_csv(final_csv)\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-input processing\n",
    "\n",
    "Prior to using the cleaned data, we need to process the data into a more readable format. This would mean fully separating into inputs and outputs as well as converting any categorical variables into binaries. \n",
    "\n",
    "To do so, we use pd.get_dummies to \"one-hot-encode\" our categorical variables to not place too much importance on any given point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pitching Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 21042 entries, 0 to 21061\n",
      "Data columns (total 28 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   left_field       21042 non-null  float64\n",
      " 1   center_field     21042 non-null  float64\n",
      " 2   right_field      21042 non-null  float64\n",
      " 3   min_wall_height  21042 non-null  float64\n",
      " 4   max_wall_height  21042 non-null  float64\n",
      " 5   attendance       21042 non-null  float64\n",
      " 6   temp             21042 non-null  float64\n",
      " 7   windspeed        21042 non-null  float64\n",
      " 8   season_era       21042 non-null  float64\n",
      " 9   daynight_day     21042 non-null  int64  \n",
      " 10  daynight_night   21042 non-null  int64  \n",
      " 11  precip_drizzle   21042 non-null  int64  \n",
      " 12  precip_none      21042 non-null  int64  \n",
      " 13  precip_rain      21042 non-null  int64  \n",
      " 14  precip_snow      21042 non-null  int64  \n",
      " 15  sky_cloudy       21042 non-null  int64  \n",
      " 16  sky_dome         21042 non-null  int64  \n",
      " 17  sky_overcast     21042 non-null  int64  \n",
      " 18  sky_sunny        21042 non-null  int64  \n",
      " 19  winddir_fromcf   21042 non-null  int64  \n",
      " 20  winddir_fromlf   21042 non-null  int64  \n",
      " 21  winddir_fromrf   21042 non-null  int64  \n",
      " 22  winddir_ltor     21042 non-null  int64  \n",
      " 23  winddir_rtol     21042 non-null  int64  \n",
      " 24  winddir_tocf     21042 non-null  int64  \n",
      " 25  winddir_tolf     21042 non-null  int64  \n",
      " 26  winddir_torf     21042 non-null  int64  \n",
      " 27  winddir_unknown  21042 non-null  int64  \n",
      "dtypes: float64(9), int64(19)\n",
      "memory usage: 4.7 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 21042 entries, 0 to 21061\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype\n",
      "---  ------    --------------  -----\n",
      " 0   p_ipouts  21042 non-null  int64\n",
      " 1   p_h       21042 non-null  int64\n",
      " 2   p_r       21042 non-null  int64\n",
      " 3   p_er      21042 non-null  int64\n",
      " 4   p_w       21042 non-null  int64\n",
      " 5   p_k       21042 non-null  int64\n",
      " 6   p_hbp     21042 non-null  int64\n",
      " 7   p_wp      21042 non-null  int64\n",
      "dtypes: int64(8)\n",
      "memory usage: 1.4 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load pitching data\n",
    "pitching_data = pd.read_csv('2023_full_pitching_stats_cleaned.csv')\n",
    "\n",
    "# Define categorical data and input/output columns\n",
    "categorical_data = ['daynight', 'precip', 'sky', 'winddir']\n",
    "\n",
    "pitching_inputs = [\n",
    "    'left_field', 'center_field', 'right_field', 'min_wall_height', 'max_wall_height',\n",
    "    'attendance', 'temp', 'windspeed', 'season_era', 'daynight_day', 'daynight_night',\n",
    "    'precip_drizzle', 'precip_none', 'precip_rain', 'precip_snow', 'sky_cloudy', 'sky_dome',\n",
    "    'sky_overcast', 'sky_sunny', 'winddir_fromcf', 'winddir_fromlf', 'winddir_fromrf',\n",
    "    'winddir_ltor', 'winddir_rtol', 'winddir_tocf', 'winddir_tolf', 'winddir_torf', 'winddir_unknown'\n",
    "]\n",
    "pitching_outputs = ['p_ipouts', 'p_h', 'p_r', 'p_er', 'p_w', 'p_k','p_hbp', 'p_wp']\n",
    "\n",
    "# Handle missing values and categorical data\n",
    "pitching_data['precip'] = pitching_data['precip'].fillna('none')\n",
    "pitching_data = pitching_data.dropna()\n",
    "pitching_data = pd.get_dummies(pitching_data, columns=categorical_data)\n",
    "\n",
    "# Post-encoding dummy variables\n",
    "p_encoded_variables = [\n",
    "    'daynight_day', 'daynight_night', 'precip_drizzle', 'precip_none', 'precip_rain',\n",
    "    'precip_snow', 'sky_cloudy', 'sky_dome', 'sky_overcast', 'sky_sunny',\n",
    "    'winddir_fromcf', 'winddir_fromlf', 'winddir_fromrf', 'winddir_ltor', 'winddir_rtol',\n",
    "    'winddir_tocf', 'winddir_tolf', 'winddir_torf', 'winddir_unknown'\n",
    "]\n",
    "\n",
    "# Convert non-dummy columns to float\n",
    "non_encoded_columns = [\n",
    "    'left_field', 'center_field', 'right_field', 'min_wall_height', 'max_wall_height',\n",
    "    'attendance', 'temp', 'windspeed', 'season_era'\n",
    "]\n",
    "pitching_data[non_encoded_columns] = pitching_data[non_encoded_columns].astype(float)\n",
    "\n",
    "# Convert dummy-encoded columns to float\n",
    "pitching_data[p_encoded_variables] = pitching_data[p_encoded_variables].astype(int)\n",
    "\n",
    "# Extract input and output data\n",
    "pitching_input_data = pitching_data[pitching_inputs]\n",
    "pitching_output_data = pitching_data[pitching_outputs]\n",
    "\n",
    "# Verify data types\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(pitching_input_data.info())\n",
    "print(pitching_output_data.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_ipouts</th>\n",
       "      <th>p_h</th>\n",
       "      <th>p_r</th>\n",
       "      <th>p_er</th>\n",
       "      <th>p_w</th>\n",
       "      <th>p_k</th>\n",
       "      <th>p_hbp</th>\n",
       "      <th>p_wp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   p_ipouts  p_h  p_r  p_er  p_w  p_k  p_hbp  p_wp\n",
       "0        15    6    4     4    1    3      1     0\n",
       "1         3    1    0     0    0    2      0     0\n",
       "2         3    0    0     0    0    0      0     0\n",
       "3         2    2    3     3    1    1      1     0\n",
       "4         1    0    0     0    0    1      0     0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pitching_input_data.head()\n",
    "pitching_output_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 49080 entries, 0 to 49118\n",
      "Data columns (total 28 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   left_field          49080 non-null  float64\n",
      " 1   center_field        49080 non-null  float64\n",
      " 2   right_field         49080 non-null  float64\n",
      " 3   min_wall_height     49080 non-null  float64\n",
      " 4   max_wall_height     49080 non-null  float64\n",
      " 5   attendance          49080 non-null  float64\n",
      " 6   temp                49080 non-null  float64\n",
      " 7   windspeed           49080 non-null  float64\n",
      " 8   season_batting_avg  49080 non-null  float64\n",
      " 9   daynight_day        49080 non-null  int64  \n",
      " 10  daynight_night      49080 non-null  int64  \n",
      " 11  precip_drizzle      49080 non-null  int64  \n",
      " 12  precip_none         49080 non-null  int64  \n",
      " 13  precip_rain         49080 non-null  int64  \n",
      " 14  precip_snow         49080 non-null  int64  \n",
      " 15  sky_cloudy          49080 non-null  int64  \n",
      " 16  sky_dome            49080 non-null  int64  \n",
      " 17  sky_overcast        49080 non-null  int64  \n",
      " 18  sky_sunny           49080 non-null  int64  \n",
      " 19  winddir_fromcf      49080 non-null  int64  \n",
      " 20  winddir_fromlf      49080 non-null  int64  \n",
      " 21  winddir_fromrf      49080 non-null  int64  \n",
      " 22  winddir_ltor        49080 non-null  int64  \n",
      " 23  winddir_rtol        49080 non-null  int64  \n",
      " 24  winddir_tocf        49080 non-null  int64  \n",
      " 25  winddir_tolf        49080 non-null  int64  \n",
      " 26  winddir_torf        49080 non-null  int64  \n",
      " 27  winddir_unknown     49080 non-null  int64  \n",
      "dtypes: float64(9), int64(19)\n",
      "memory usage: 10.9 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 49080 entries, 0 to 49118\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   b_ab    49080 non-null  int64\n",
      " 1   b_h     49080 non-null  int64\n",
      " 2   b_d     49080 non-null  int64\n",
      " 3   b_t     49080 non-null  int64\n",
      " 4   b_hr    49080 non-null  int64\n",
      " 5   b_rbi   49080 non-null  int64\n",
      " 6   b_w     49080 non-null  int64\n",
      " 7   b_k     49080 non-null  int64\n",
      "dtypes: int64(8)\n",
      "memory usage: 3.4 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "batting_data = pd.read_csv('2023_complete_batting_data.csv', low_memory=False)\n",
    "\n",
    "# Define input and output columns\n",
    "batting_inputs = [\n",
    "    'left_field', 'center_field', 'right_field', 'min_wall_height', 'max_wall_height',\n",
    "    'attendance', 'temp', 'windspeed', 'season_batting_avg', 'daynight_day', 'daynight_night',\n",
    "    'precip_drizzle', 'precip_none', 'precip_rain', 'precip_snow', 'sky_cloudy', 'sky_dome',\n",
    "    'sky_overcast', 'sky_sunny', 'winddir_fromcf', 'winddir_fromlf', 'winddir_fromrf',\n",
    "    'winddir_ltor', 'winddir_rtol', 'winddir_tocf', 'winddir_tolf', 'winddir_torf', 'winddir_unknown'\n",
    "]\n",
    "batting_outputs = ['b_ab', 'b_h', 'b_d', 'b_t', 'b_hr', 'b_rbi', 'b_w', 'b_k']\n",
    "\n",
    "# Handle missing and categorical data\n",
    "batting_data['precip'] = batting_data['precip'].fillna('none')\n",
    "batting_data = batting_data.dropna()\n",
    "categorical_data = ['daynight', 'precip', 'sky', 'winddir']\n",
    "batting_data = pd.get_dummies(batting_data, columns=categorical_data)\n",
    "\n",
    "# Post-encoding dummy variables\n",
    "b_encoded_variables = [\n",
    "    'daynight_day', 'daynight_night', 'precip_drizzle', 'precip_none', 'precip_rain',\n",
    "    'precip_snow', 'sky_cloudy', 'sky_dome', 'sky_overcast', 'sky_sunny',\n",
    "    'winddir_fromcf', 'winddir_fromlf', 'winddir_fromrf', 'winddir_ltor', 'winddir_rtol',\n",
    "    'winddir_tocf', 'winddir_tolf', 'winddir_torf', 'winddir_unknown'\n",
    "]\n",
    "\n",
    "# Convert non-dummy columns to float\n",
    "non_encoded_columns = [\n",
    "    'left_field', 'center_field', 'right_field', 'min_wall_height', 'max_wall_height',\n",
    "    'attendance', 'temp', 'windspeed', 'season_batting_avg'\n",
    "]\n",
    "batting_data[non_encoded_columns] = batting_data[non_encoded_columns].astype(float)\n",
    "\n",
    "# Convert dummy-encoded columns to float\n",
    "batting_data[b_encoded_variables] = batting_data[b_encoded_variables].astype(int)\n",
    "\n",
    "# Extract input and output data\n",
    "batting_input_data = batting_data[batting_inputs]\n",
    "batting_output_data = batting_data[batting_outputs]\n",
    "\n",
    "# Verify data types\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(batting_input_data.info())\n",
    "print(batting_output_data.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_field</th>\n",
       "      <th>center_field</th>\n",
       "      <th>right_field</th>\n",
       "      <th>min_wall_height</th>\n",
       "      <th>max_wall_height</th>\n",
       "      <th>attendance</th>\n",
       "      <th>temp</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>season_era</th>\n",
       "      <th>daynight_day</th>\n",
       "      <th>daynight_night</th>\n",
       "      <th>precip_drizzle</th>\n",
       "      <th>precip_none</th>\n",
       "      <th>precip_rain</th>\n",
       "      <th>precip_snow</th>\n",
       "      <th>sky_cloudy</th>\n",
       "      <th>sky_dome</th>\n",
       "      <th>sky_overcast</th>\n",
       "      <th>sky_sunny</th>\n",
       "      <th>winddir_fromcf</th>\n",
       "      <th>winddir_fromlf</th>\n",
       "      <th>winddir_fromrf</th>\n",
       "      <th>winddir_ltor</th>\n",
       "      <th>winddir_rtol</th>\n",
       "      <th>winddir_tocf</th>\n",
       "      <th>winddir_tolf</th>\n",
       "      <th>winddir_torf</th>\n",
       "      <th>winddir_unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>310.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>36049.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.708</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>310.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>36049.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.845</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>310.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>36049.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.436</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>310.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>36049.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.169</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>310.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>36049.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   left_field  center_field  right_field  min_wall_height  max_wall_height  \\\n",
       "0       310.0         420.0        302.0              3.0             37.0   \n",
       "1       310.0         420.0        302.0              3.0             37.0   \n",
       "2       310.0         420.0        302.0              3.0             37.0   \n",
       "3       310.0         420.0        302.0              3.0             37.0   \n",
       "4       310.0         420.0        302.0              3.0             37.0   \n",
       "\n",
       "   attendance  temp  windspeed  season_era  daynight_day  daynight_night  \\\n",
       "0     36049.0  38.0       12.0       4.708             1               0   \n",
       "1     36049.0  38.0       12.0       6.845             1               0   \n",
       "2     36049.0  38.0       12.0       3.436             1               0   \n",
       "3     36049.0  38.0       12.0       4.169             1               0   \n",
       "4     36049.0  38.0       12.0       6.000             1               0   \n",
       "\n",
       "   precip_drizzle  precip_none  precip_rain  precip_snow  sky_cloudy  \\\n",
       "0               0            1            0            0           0   \n",
       "1               0            1            0            0           0   \n",
       "2               0            1            0            0           0   \n",
       "3               0            1            0            0           0   \n",
       "4               0            1            0            0           0   \n",
       "\n",
       "   sky_dome  sky_overcast  sky_sunny  winddir_fromcf  winddir_fromlf  \\\n",
       "0         0             0          1               0               0   \n",
       "1         0             0          1               0               0   \n",
       "2         0             0          1               0               0   \n",
       "3         0             0          1               0               0   \n",
       "4         0             0          1               0               0   \n",
       "\n",
       "   winddir_fromrf  winddir_ltor  winddir_rtol  winddir_tocf  winddir_tolf  \\\n",
       "0               0             1             0             0             0   \n",
       "1               0             1             0             0             0   \n",
       "2               0             1             0             0             0   \n",
       "3               0             1             0             0             0   \n",
       "4               0             1             0             0             0   \n",
       "\n",
       "   winddir_torf  winddir_unknown  \n",
       "0             0                0  \n",
       "1             0                0  \n",
       "2             0                0  \n",
       "3             0                0  \n",
       "4             0                0  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pitching_input_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For predictions, we are also going to use average valuesand modes. For numerical data we will use the mean. For categorical datas, we will use the mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Tune or Neural Network (NN), we are using different numbers. To do so, we will use the gridsearch CV function to process our Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements for Neural Networks\n",
    "import sklearn as sk\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To support our multi-output classifier, we needed to create a multioutput evaluation method to score our tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multioutput_accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute accuracy for multi-output targets.\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    accuracies = [\n",
    "        accuracy_score(y_true[:, i], y_pred[:, i])\n",
    "        for i in range(y_true.shape[1])\n",
    "    ]\n",
    "    return np.mean(accuracies)\n",
    "\n",
    "\n",
    "\n",
    "multioutput_scorer = make_scorer(multioutput_accuracy, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we will start with our pitching neural network. We start off with scaling our data and reducing our number of dimensions. From there, we will run it through our MLPClassifier Algorithm from Sci-kit learn. We will determine what hyperparameters work best for our neural network by using the GridSearchCV function to get a cross validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nested cross-validation scores: [0.56062537 0.56649415 0.56720672]\n",
      "Mean Accuracy:  56.47754150040078\n"
     ]
    }
   ],
   "source": [
    "# Create Pipeline of processes to run through\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "pline = Pipeline([('scaling', sk.preprocessing.StandardScaler()), ('pca', PCA()),\n",
    "                  ('nnet', MultiOutputClassifier(MLPClassifier( early_stopping= True)))])\n",
    "\n",
    "# Defines Parameters to Test\n",
    "param_grid = {\n",
    "    'pca__n_components':[5, 7, 9],\n",
    "    'nnet__estimator__hidden_layer_sizes':[10,20,30],\n",
    "    'nnet__estimator__activation': ['relu'],\n",
    "    'nnet__estimator__alpha':[0.0001,0.01],\n",
    "    'nnet__estimator__max_iter':[500, 1000]\n",
    "}\n",
    "\n",
    "# Subsample the data for grid search (randomly selecting 10,000 samples)\n",
    "gs_pitching_input_data = pitching_input_data.sample(n=10000, random_state=42)\n",
    "gs_pitching_output_data = pitching_output_data.loc[gs_pitching_input_data.index]\n",
    "\n",
    "\n",
    "# Grid Search + Scoring\n",
    "gs = GridSearchCV(pline, param_grid, cv=kf, scoring=multioutput_scorer, n_jobs=-1)\n",
    "\n",
    "# Cross-validate using the subsampled data\n",
    "pitching_nested_score = cross_val_score(gs, gs_pitching_input_data.values, gs_pitching_output_data.values, \n",
    "                                        cv=kf,scoring=multioutput_scorer, n_jobs=-1)\n",
    "\n",
    "print(\"Nested cross-validation scores:\", pitching_nested_score)\n",
    "print(\"Mean Accuracy: \", pitching_nested_score.mean() * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nnet__estimator__activation': 'relu', 'nnet__estimator__alpha': 0.0001, 'nnet__estimator__hidden_layer_sizes': 20, 'nnet__estimator__max_iter': 500, 'pca__n_components': 5}\n"
     ]
    }
   ],
   "source": [
    "# Extract the Best Parameters\n",
    "gs.fit(pitching_input_data, pitching_output_data)\n",
    "best_params = gs.best_params_\n",
    "print(best_params)\n",
    "\n",
    "\n",
    "#{'nnet__estimator__activation': 'relu', 'nnet__estimator__alpha': 0.0001, 'nnet__estimator__hidden_layer_sizes': 30, 'pca__n_components': 5} From previous try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model training completed.\n",
      "Test Accuracy: 56.36%\n",
      "Classification Report for p_ipouts:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        35\n",
      "           1       0.00      0.00      0.00       281\n",
      "           2       0.00      0.00      0.00       380\n",
      "           3       0.41      1.00      0.58      1734\n",
      "           4       0.00      0.00      0.00       226\n",
      "           5       0.00      0.00      0.00       146\n",
      "           6       0.00      0.00      0.00       285\n",
      "           7       0.00      0.00      0.00        40\n",
      "           8       0.00      0.00      0.00        35\n",
      "           9       0.00      0.00      0.00        81\n",
      "          10       0.00      0.00      0.00        36\n",
      "          11       0.00      0.00      0.00        35\n",
      "          12       0.00      0.00      0.00        80\n",
      "          13       0.00      0.00      0.00        40\n",
      "          14       0.00      0.00      0.00        66\n",
      "          15       0.00      0.00      0.00       203\n",
      "          16       0.00      0.00      0.00        48\n",
      "          17       0.00      0.00      0.00        53\n",
      "          18       0.00      0.00      0.00       229\n",
      "          19       0.00      0.00      0.00        25\n",
      "          20       0.00      0.00      0.00        20\n",
      "          21       0.00      0.00      0.00        93\n",
      "          22       0.00      0.00      0.00         5\n",
      "          23       0.00      0.00      0.00         8\n",
      "          24       0.00      0.00      0.00        16\n",
      "          26       0.00      0.00      0.00         1\n",
      "          27       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.41      4209\n",
      "   macro avg       0.02      0.04      0.02      4209\n",
      "weighted avg       0.17      0.41      0.24      4209\n",
      "\n",
      "Classification Report for p_h:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.92      0.47      1344\n",
      "           1       0.28      0.08      0.13      1048\n",
      "           2       0.00      0.00      0.00       575\n",
      "           3       0.00      0.00      0.00       366\n",
      "           4       0.00      0.00      0.00       240\n",
      "           5       0.00      0.00      0.00       184\n",
      "           6       0.00      0.00      0.00       180\n",
      "           7       0.00      0.00      0.00       126\n",
      "           8       0.00      0.00      0.00        72\n",
      "           9       0.00      0.00      0.00        43\n",
      "          10       0.00      0.00      0.00        25\n",
      "          11       0.00      0.00      0.00         5\n",
      "          13       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.32      4209\n",
      "   macro avg       0.05      0.08      0.05      4209\n",
      "weighted avg       0.17      0.32      0.18      4209\n",
      "\n",
      "Classification Report for p_r:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      1.00      0.71      2330\n",
      "           1       0.00      0.00      0.00       704\n",
      "           2       0.00      0.00      0.00       427\n",
      "           3       0.00      0.00      0.00       306\n",
      "           4       0.00      0.00      0.00       202\n",
      "           5       0.00      0.00      0.00       125\n",
      "           6       0.00      0.00      0.00        54\n",
      "           7       0.00      0.00      0.00        39\n",
      "           8       0.00      0.00      0.00        15\n",
      "           9       0.00      0.00      0.00         6\n",
      "          10       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.55      4209\n",
      "   macro avg       0.05      0.09      0.06      4209\n",
      "weighted avg       0.31      0.55      0.39      4209\n",
      "\n",
      "Classification Report for p_er:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      1.00      0.73      2427\n",
      "           1       0.00      0.00      0.00       678\n",
      "           2       0.00      0.00      0.00       424\n",
      "           3       0.00      0.00      0.00       284\n",
      "           4       0.00      0.00      0.00       185\n",
      "           5       0.00      0.00      0.00       108\n",
      "           6       0.00      0.00      0.00        53\n",
      "           7       0.00      0.00      0.00        30\n",
      "           8       0.00      0.00      0.00        14\n",
      "           9       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.58      4209\n",
      "   macro avg       0.06      0.10      0.07      4209\n",
      "weighted avg       0.33      0.58      0.42      4209\n",
      "\n",
      "Classification Report for p_w:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      1.00      0.69      2216\n",
      "           1       0.12      0.00      0.01      1159\n",
      "           2       0.00      0.00      0.00       506\n",
      "           3       0.00      0.00      0.00       202\n",
      "           4       0.00      0.00      0.00        88\n",
      "           5       0.00      0.00      0.00        24\n",
      "           6       0.00      0.00      0.00        11\n",
      "           7       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.52      4209\n",
      "   macro avg       0.08      0.12      0.09      4209\n",
      "weighted avg       0.31      0.52      0.36      4209\n",
      "\n",
      "Classification Report for p_k:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.05      0.08       976\n",
      "           1       0.30      0.95      0.46      1265\n",
      "           2       0.00      0.00      0.00       811\n",
      "           3       0.00      0.00      0.00       370\n",
      "           4       0.00      0.00      0.00       218\n",
      "           5       0.00      0.00      0.00       177\n",
      "           6       0.00      0.00      0.00       129\n",
      "           7       0.00      0.00      0.00       113\n",
      "           8       0.00      0.00      0.00        53\n",
      "           9       0.00      0.00      0.00        45\n",
      "          10       0.00      0.00      0.00        31\n",
      "          11       0.00      0.00      0.00         7\n",
      "          12       0.00      0.00      0.00         9\n",
      "          13       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.30      4209\n",
      "   macro avg       0.04      0.07      0.04      4209\n",
      "weighted avg       0.14      0.30      0.16      4209\n",
      "\n",
      "Classification Report for p_hbp:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      3821\n",
      "           1       0.00      0.00      0.00       359\n",
      "           2       0.00      0.00      0.00        25\n",
      "           3       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.91      4209\n",
      "   macro avg       0.23      0.25      0.24      4209\n",
      "weighted avg       0.82      0.91      0.86      4209\n",
      "\n",
      "Classification Report for p_wp:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      3882\n",
      "           1       0.00      0.00      0.00       304\n",
      "           2       0.00      0.00      0.00        21\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.92      4209\n",
      "   macro avg       0.18      0.20      0.19      4209\n",
      "weighted avg       0.85      0.92      0.89      4209\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Generate Final Algorithm\n",
    "\n",
    "X_train, X_test, y_train, y_test = sk.model_selection.train_test_split(\n",
    "    pitching_input_data.values,  # Ensure NumPy arrays\n",
    "    pitching_output_data.values, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Generate Final Algorithm with the best parameters\n",
    "final_model = Pipeline([\n",
    "    ('scaling', sk.preprocessing.StandardScaler()), \n",
    "    ('pca', PCA(n_components=best_params['pca__n_components'])),\n",
    "    ('nnet', MultiOutputClassifier(MLPClassifier(\n",
    "        activation=best_params['nnet__estimator__activation'],\n",
    "        hidden_layer_sizes=best_params['nnet__estimator__hidden_layer_sizes'],\n",
    "        alpha=best_params['nnet__estimator__alpha'],\n",
    "        max_iter=best_params['nnet__estimator__max_iter'],\n",
    "        early_stopping=True\n",
    "    )))\n",
    "])\n",
    "\n",
    "# Train the final model on the training set\n",
    "final_model.fit(X_train, y_train)\n",
    "print(\"Final model training completed.\")\n",
    "\n",
    "y_pred = final_model.predict(X_test)\n",
    "# Compute and print the accuracy\n",
    "test_accuracy = multioutput_accuracy(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Generate detailed classification reports for each output variable\n",
    "for i, col in enumerate(pitching_output_data.columns):\n",
    "    print(f\"Classification Report for {col}:\")\n",
    "    print(sk.metrics.classification_report(y_test[:, i], y_pred[:, i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved as 'pitching_model.pkl'.\n"
     ]
    }
   ],
   "source": [
    "with open(\"pitching_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(final_model, f)\n",
    "print(\"Final model saved as 'pitching_model.pkl'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitching_model = pickle.load(open('pitching_model_kf.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PermutationExplainer explainer:  61%|██████    | 2558/4209 [12:02<07:49,  3.52it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Create a SHAP explainer\u001b[39;00m\n\u001b[1;32m     17\u001b[0m explainer \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mExplainer(wrapped_model\u001b[38;5;241m.\u001b[39mpredict, X_train)\n\u001b[0;32m---> 18\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Plot SHAP summary for the analyzed output\u001b[39;00m\n\u001b[1;32m     21\u001b[0m shap\u001b[38;5;241m.\u001b[39msummary_plot(shap_values, X_test, feature_names\u001b[38;5;241m=\u001b[39mpitching_input_data\u001b[38;5;241m.\u001b[39mcolumns)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/shap/explainers/_permutation.py:77\u001b[0m, in \u001b[0;36mPermutationExplainer.__call__\u001b[0;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *args)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, max_evals\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, main_effects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, error_bounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     75\u001b[0m              outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     76\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Explain the output of the model on the given arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmain_effects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmain_effects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_bounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_bounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/shap/explainers/_explainer.py:266\u001b[0m, in \u001b[0;36mExplainer.__call__\u001b[0;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *args, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     feature_names \u001b[38;5;241m=\u001b[39m [[] \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(args))]\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row_args \u001b[38;5;129;01min\u001b[39;00m show_progress(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39margs), num_rows, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m explainer\u001b[39m\u001b[38;5;124m\"\u001b[39m, silent):\n\u001b[0;32m--> 266\u001b[0m     row_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_row\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrow_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmain_effects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmain_effects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_bounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_bounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m     values\u001b[38;5;241m.\u001b[39mappend(row_result\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    271\u001b[0m     output_indices\u001b[38;5;241m.\u001b[39mappend(row_result\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_indices\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/shap/explainers/_permutation.py:133\u001b[0m, in \u001b[0;36mPermutationExplainer.explain_row\u001b[0;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *row_args)\u001b[0m\n\u001b[1;32m    130\u001b[0m     i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# evaluate the masked model\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzero_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m row_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    136\u001b[0m     row_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(fm),) \u001b[38;5;241m+\u001b[39m outputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/shap/utils/_masked_model.py:60\u001b[0m, in \u001b[0;36mMaskedModel.__call__\u001b[0;34m(self, masks, zero_index, batch_size)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(masks\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmasker, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupports_delta_masking\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m---> 60\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_delta_masking_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzero_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# we need to convert from delta masking to a full masking call because we were given a delta masking\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;66;03m# input but the masker does not support delta masking\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m         full_masks \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39msum(masks \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_masker_cols), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/shap/utils/_masked_model.py:206\u001b[0m, in \u001b[0;36mMaskedModel._delta_masking_call\u001b[0;34m(self, masks, zero_index, batch_size)\u001b[0m\n\u001b[1;32m    203\u001b[0m     batch_positions[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m batch_positions[i] \u001b[38;5;241m+\u001b[39m num_varying_rows[i]\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m# joined_masked_inputs = self._stack_inputs(all_masked_inputs)\u001b[39;00m\n\u001b[0;32m--> 206\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msubset_masked_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m _assert_output_input_match(subset_masked_inputs, outputs)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinearize_link \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlink \u001b[38;5;241m!=\u001b[39m links\u001b[38;5;241m.\u001b[39midentity \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_linearizing_weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/shap/models/_model.py:21\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m---> 21\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     is_tensor \u001b[38;5;241m=\u001b[39m safe_isinstance(out, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mif\u001b[39;00m is_tensor \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(out)\n",
      "Cell \u001b[0;32mIn[36], line 10\u001b[0m, in \u001b[0;36mMultiOutputPipelineWrapper.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Predict only for the specified output\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/pipeline.py:601\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[0;34m(self, X, **params)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    600\u001b[0m         Xt \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mtransform(Xt)\n\u001b[0;32m--> 601\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;66;03m# metadata routing enabled\u001b[39;00m\n\u001b[1;32m    604\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m process_routing(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/multioutput.py:310\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe base estimator should implement a predict method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 310\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimators_\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(y)\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1163\u001b[0m, in \u001b[0;36mMLPClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict using the multi-layer perceptron classifier.\u001b[39;00m\n\u001b[1;32m   1151\u001b[0m \n\u001b[1;32m   1152\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[38;5;124;03m    The predicted classes.\u001b[39;00m\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1162\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 1163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1167\u001b[0m, in \u001b[0;36mMLPClassifier._predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Private predict method with optional input validation\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1167\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_pass_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1170\u001b[0m         y_pred \u001b[38;5;241m=\u001b[39m y_pred\u001b[38;5;241m.\u001b[39mravel()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:214\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._forward_pass_fast\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    212\u001b[0m hidden_activation \u001b[38;5;241m=\u001b[39m ACTIVATIONS[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation]\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_layers_ \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 214\u001b[0m     activation \u001b[38;5;241m=\u001b[39m \u001b[43msafe_sparse_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoefs_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m     activation \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercepts_[i]\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_layers_ \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/extmath.py:208\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    205\u001b[0m     ret \u001b[38;5;241m=\u001b[39m a \u001b[38;5;241m@\u001b[39m b\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m--> 208\u001b[0m     \u001b[43msparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43missparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(b)\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    212\u001b[0m ):\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/scipy/sparse/_base.py:1291\u001b[0m, in \u001b[0;36misspmatrix\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1288\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder)\n\u001b[0;32m-> 1291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21misspmatrix\u001b[39m(x):\n\u001b[1;32m   1292\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Is x of a sparse matrix type?\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \n\u001b[1;32m   1294\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[1;32m   1317\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, spmatrix)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import shap\n",
    "\n",
    "class MultiOutputPipelineWrapper:\n",
    "    def __init__(self, pipeline, target_index):\n",
    "        self.pipeline = pipeline\n",
    "        self.target_index = target_index\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Predict only for the specified output\n",
    "        return self.pipeline.predict(X)[:, self.target_index]\n",
    "\n",
    "# Wrap your pipeline for a specific target (e.g., `p_ipouts`)\n",
    "target_index = 0  # Specify the index of the output you want to analyze\n",
    "wrapped_model = MultiOutputPipelineWrapper(pitching_model, target_index)\n",
    "\n",
    "# Create a SHAP explainer\n",
    "explainer = shap.Explainer(wrapped_model.predict, X_train)\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "# Plot SHAP summary for the analyzed output\n",
    "shap.summary_plot(shap_values, X_test, feature_names=pitching_input_data.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batting Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nested cross-validation scores: [0.67321536 0.66824182 0.67075458]\n",
      "Mean Accuracy:  67.0737252189526\n"
     ]
    }
   ],
   "source": [
    "# Create Pipeline of processes to run through\n",
    "pline2 = Pipeline([('scaling', sk.preprocessing.StandardScaler()), ('pca', PCA()),\n",
    "                   ('nnet', MultiOutputClassifier(MLPClassifier(max_iter=1000, early_stopping=True)))])\n",
    "\n",
    "# Defines Parameters to Test\n",
    "param_grid2 = {\n",
    "    'pca__n_components':[5, 7, 9],\n",
    "    'nnet__estimator__hidden_layer_sizes':[10,20,30],\n",
    "    'nnet__estimator__activation': ['relu'],\n",
    "    'nnet__estimator__alpha':[0.0001,0.01],\n",
    "    'nnet__estimator__max_iter':[500, 1000]\n",
    "}\n",
    "\n",
    "# Subsample the data for grid search\n",
    "gs_batting_input_data = batting_input_data.sample(10000, random_state=42)\n",
    "gs_batting_output_data = batting_output_data.sample(10000, random_state=42)\n",
    "\n",
    "# Grid Search + Scoring\n",
    "gs2 = GridSearchCV(pline2, param_grid2, cv=5, scoring=multioutput_scorer, n_jobs=-1)\n",
    "\n",
    "# Cross-validate using the subsampled data\n",
    "batting_nested_score = cross_val_score(gs2, \n",
    "                                       gs_batting_input_data.values, \n",
    "                                       gs_batting_output_data.values, \n",
    "                                       cv=3, \n",
    "                                       scoring=multioutput_scorer, \n",
    "                                       n_jobs=-1)\n",
    "\n",
    "print(\"Nested cross-validation scores:\", batting_nested_score)\n",
    "print(\"Mean Accuracy: \", batting_nested_score.mean() * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nnet__estimator__activation': 'relu', 'nnet__estimator__alpha': 0.01, 'nnet__estimator__hidden_layer_sizes': 30, 'nnet__estimator__max_iter': 1000, 'pca__n_components': 7}\n"
     ]
    }
   ],
   "source": [
    "# Extract the Best Parameters\n",
    "gs2.fit(batting_input_data, batting_output_data)\n",
    "best_params2 = gs2.best_params_\n",
    "print(best_params2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model training completed.\n",
      "Test Accuracy: 67.37%\n",
      "Classification Report for b_ab:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       825\n",
      "           2       0.00      0.00      0.00      1036\n",
      "           3       0.34      0.01      0.02      2648\n",
      "           4       0.42      0.99      0.59      4120\n",
      "           5       0.00      0.00      0.00      1127\n",
      "           6       0.00      0.00      0.00        56\n",
      "           7       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.42      9816\n",
      "   macro avg       0.11      0.14      0.09      9816\n",
      "weighted avg       0.27      0.42      0.25      9816\n",
      "\n",
      "Classification Report for b_h:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.74      0.54      4087\n",
      "           1       0.38      0.28      0.32      3731\n",
      "           2       0.00      0.00      0.00      1564\n",
      "           3       0.00      0.00      0.00       367\n",
      "           4       0.00      0.00      0.00        60\n",
      "           5       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.41      9816\n",
      "   macro avg       0.13      0.17      0.14      9816\n",
      "weighted avg       0.32      0.41      0.35      9816\n",
      "\n",
      "Classification Report for b_d:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92      8304\n",
      "           1       0.00      0.00      0.00      1385\n",
      "           2       0.00      0.00      0.00       121\n",
      "           3       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.85      9816\n",
      "   macro avg       0.21      0.25      0.23      9816\n",
      "weighted avg       0.72      0.85      0.78      9816\n",
      "\n",
      "Classification Report for b_t:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      9676\n",
      "           1       0.00      0.00      0.00       137\n",
      "           2       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.99      9816\n",
      "   macro avg       0.33      0.33      0.33      9816\n",
      "weighted avg       0.97      0.99      0.98      9816\n",
      "\n",
      "Classification Report for b_hr:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94      8654\n",
      "           1       0.00      0.00      0.00      1094\n",
      "           2       0.00      0.00      0.00        66\n",
      "           3       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.88      9816\n",
      "   macro avg       0.22      0.25      0.23      9816\n",
      "weighted avg       0.78      0.88      0.83      9816\n",
      "\n",
      "Classification Report for b_rbi:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83      6945\n",
      "           1       0.00      0.00      0.00      1837\n",
      "           2       0.00      0.00      0.00       704\n",
      "           3       0.00      0.00      0.00       220\n",
      "           4       0.00      0.00      0.00        80\n",
      "           5       0.00      0.00      0.00        23\n",
      "           6       0.00      0.00      0.00         4\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.71      9816\n",
      "   macro avg       0.08      0.11      0.09      9816\n",
      "weighted avg       0.50      0.71      0.59      9816\n",
      "\n",
      "Classification Report for b_w:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.84      7134\n",
      "           1       0.00      0.00      0.00      2195\n",
      "           2       0.00      0.00      0.00       442\n",
      "           3       0.00      0.00      0.00        44\n",
      "           4       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.73      9816\n",
      "   macro avg       0.15      0.20      0.17      9816\n",
      "weighted avg       0.53      0.73      0.61      9816\n",
      "\n",
      "Classification Report for b_k:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.64      0.50      3939\n",
      "           1       0.40      0.39      0.40      3818\n",
      "           2       0.00      0.00      0.00      1633\n",
      "           3       0.00      0.00      0.00       383\n",
      "           4       0.00      0.00      0.00        41\n",
      "           5       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.41      9816\n",
      "   macro avg       0.14      0.17      0.15      9816\n",
      "weighted avg       0.32      0.41      0.36      9816\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mathew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train2, X_test2, y_train2, y_test2 = sk.model_selection.train_test_split(\n",
    "    batting_input_data.values,  # Ensure NumPy arrays\n",
    "    batting_output_data.values, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Generate Final Algorithm with the best parameters\n",
    "final_model2 = Pipeline([\n",
    "    ('scaling', sk.preprocessing.StandardScaler()), \n",
    "    ('pca', PCA(n_components=best_params2['pca__n_components'])),\n",
    "    ('nnet', MultiOutputClassifier(MLPClassifier(\n",
    "        activation=best_params2['nnet__estimator__activation'],\n",
    "        hidden_layer_sizes=best_params2['nnet__estimator__hidden_layer_sizes'],\n",
    "        alpha=best_params2['nnet__estimator__alpha'],\n",
    "        max_iter=1000,\n",
    "        early_stopping=True\n",
    "    )))\n",
    "])\n",
    "\n",
    "# Train the final model on the training set\n",
    "final_model2.fit(X_train2, y_train2)\n",
    "print(\"Final model training completed.\")\n",
    "\n",
    "# Test the model and compute predictions\n",
    "y_pred2 = final_model2.predict(X_test2)\n",
    "\n",
    "# Compute and print the accuracy\n",
    "test_accuracy2 = multioutput_accuracy(y_test2, y_pred2)\n",
    "print(f\"Test Accuracy: {test_accuracy2 * 100:.2f}%\")\n",
    "\n",
    "# Generate detailed classification reports for each output variable\n",
    "for i, col in enumerate(batting_output_data.columns):\n",
    "    print(f\"Classification Report for {col}:\")\n",
    "    print(sk.metrics.classification_report(y_test2[:, i], y_pred2[:, i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved as 'batting_model.pkl'.\n"
     ]
    }
   ],
   "source": [
    "with open(\"batting_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(final_model2, f)\n",
    "print(\"Final model saved as 'batting_model.pkl'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Model\n",
    "\n",
    "After tuning and training the model, we will now use the model. You can load in the model by using the Pickle load method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pitching model imported from 'pitching_model.pkl' as pitching_model\n"
     ]
    }
   ],
   "source": [
    "pitching_model = pickle.load(open('pitching_model.pkl', 'rb'))\n",
    "print(\"Pitching model imported from 'pitching_model.pkl' as pitching_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of the Player Class\n",
    "\n",
    "We created the base player class to have the player object contain all the non-player based classification data and then have it separate with subclasses as pitchers and batters. We included default values for environmental and player stats.\n",
    "\n",
    "For batters, we have an average batting average of 0.226\n",
    "\n",
    "For pitchers, we have an average season ERA of 5.870"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For environmental variables, we used either the mean of numerical values or used the mode of categorical variables. \n",
    "This provided us with stadium values of the following:\n",
    "\n",
    "Average Column Values:  \n",
    "left_field         331.833333  \n",
    "center_field       404.166667  \n",
    "right_field        328.333333  \n",
    "min_wall_height      7.553333  \n",
    "max_wall_height     14.266667  \n",
    "  \n",
    "We also got game variables of the following:  \n",
    "\n",
    "Average Values for Numeric Columns:  \n",
    "attendance    29356.347087  \n",
    "temp             72.413835  \n",
    "windspeed         6.466828  \n",
    "  \n",
    "Most Frequent Values for Categorical Columns:  \n",
    "daynight      night  \n",
    "precip         none  \n",
    "sky          cloudy  \n",
    "winddir     unknown  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player:\n",
    "    left_field, center_field, right_field, min_wall_height, max_wall_height, attendance, temp, windspeed = (-1,) * 8\n",
    "    daynight, precip, sky, winddir = ('',)*4\n",
    "    def __init__(self, name = 'unknown', lf = 331.833, cf = 404.167, rf = 328.333, min_wh = 7.553, max_wh = 14.27, att = 29356,\n",
    "                 t = 72.414, ws = 6.467, dn = 'night', pp = 'none', s = 'cloudy', wd = 'unknown'):\n",
    "        self.name = name\n",
    "        self.left_field = lf\n",
    "        self.center_field = cf\n",
    "        self.right_field = rf\n",
    "        self.min_wall_height= min_wh\n",
    "        self.max_wall_height = max_wh\n",
    "        self.attendance = att\n",
    "        self.temp = t \n",
    "        self.windspeed = ws\n",
    "        self.daynight = dn \n",
    "        self.precip = pp\n",
    "        self.sky = s\n",
    "        self.winddir = wd\n",
    "        self.stat = -1\n",
    "\n",
    "    def get_name(self):\n",
    "        return self.name\n",
    "\n",
    "    #one-hot-encode helper method\n",
    "    def one_hot_encode(self, value, categories):\n",
    "        return [1 if value == category else 0 for category in categories]\n",
    "\n",
    "    def __iter__(self):\n",
    "        # Base numeric features\n",
    "        features = [\n",
    "            self.left_field, \n",
    "            self.center_field, \n",
    "            self.right_field, \n",
    "            self.min_wall_height, \n",
    "            self.max_wall_height, \n",
    "            self.attendance, \n",
    "            self.temp, \n",
    "            self.windspeed,\n",
    "            self.stat #for batter or pitcher\n",
    "        ]\n",
    "\n",
    "        # One-hot encode categorical variables\n",
    "        features += self.one_hot_encode(self.daynight, ['day', 'night'])\n",
    "        features += self.one_hot_encode(self.precip, ['drizzle', 'none', 'rain', 'snow'])\n",
    "        features += self.one_hot_encode(self.sky, ['cloudy', 'dome', 'overcast', 'sunny'])\n",
    "        features += self.one_hot_encode(self.winddir, [\n",
    "            'fromcf', 'fromlf', 'fromrf', 'ltor', 'rtol', 'tocf', 'tolf', 'torf', 'unknown'\n",
    "        ])\n",
    "\n",
    "        return iter(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pitcher(Player):\n",
    "    def __init__(self, era=5.870, **kwargs):\n",
    "        super().__init__(**kwargs)  # Pass all parent arguments to Player\n",
    "        self.stat = era  # Set ERA as the stat\n",
    "\n",
    "\n",
    "class Batter(Player):\n",
    "    def __init__(self, batting_avg=0.226, **kwargs):\n",
    "        super().__init__(**kwargs)  # Pass all parent arguments to Player\n",
    "        self.stat = batting_avg  # Set batting average as the stat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "bob = Pitcher()\n",
    "pred =pitching_model.predict(np.array(list(bob)).reshape(1,-1))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get players season average (era if pitcher, batting avg if batter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skrut\\AppData\\Local\\Temp\\ipykernel_28788\\1425010776.py:9: DtypeWarning: Columns (15,16,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  batting_data = pd.read_csv(batting_file)\n"
     ]
    }
   ],
   "source": [
    "name = input(\"Enter a player's name: \").lower()\n",
    "\n",
    "def get_season_avg(name):\n",
    "\n",
    "    pitching_file = '2023_full_pitching_stats_cleaned.csv'\n",
    "    batting_file = '2023_full_batting_stats_cleaned.csv'\n",
    "\n",
    "    pitching_data = pd.read_csv(pitching_file)\n",
    "    batting_data = pd.read_csv(batting_file)\n",
    "\n",
    "    name_column = 'id'\n",
    "    batting_avg_column = 'season_batting_avg'\n",
    "    era_avg_column = 'season_era'\n",
    "\n",
    "    batting_data[name_column] = batting_data[name_column].str.lower()\n",
    "    pitching_data[name_column] = pitching_data[name_column].str.lower()\n",
    "    \n",
    "    if name in batting_data[name_column].values and name in pitching_data[name_column].values:\n",
    "        batter_avg = batting_data[batting_data[name_column] == name][batting_avg_column].values[0]\n",
    "        era_avg = pitching_data[pitching_data[name_column] == name][era_avg_column].values[0]\n",
    "        spec = input(\"Pitcher or Batter: (p or b)\").lower()\n",
    "        if spec == 'p':\n",
    "            return Pitcher(era = float(era_avg))\n",
    "        else:\n",
    "            return Batter(batting_avg = float(batter_avg))\n",
    "\n",
    "    elif name in batting_data[name_column].values:\n",
    "        batter_avg = batting_data[batting_data[name_column] == name][batting_avg_column].values[0]\n",
    "        return Batter(batting_avg = float(batter_avg))\n",
    "\n",
    "    elif name in pitching_data[name_column].values:\n",
    "        era_avg = pitching_data[pitching_data[name_column] == name][era_avg_column].values[0]\n",
    "        return Pitcher(era = float(era_avg))\n",
    "    \n",
    "    else:\n",
    "        spec = input(\"Pitcher or Batter: (p or b)\").lower()\n",
    "        if spec == 'p':\n",
    "            return Pitcher()\n",
    "        else:\n",
    "            return Batter()\n",
    "        \n",
    "\n",
    "jose = get_season_avg(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[331.833, 404.167, 328.333, 7.553, 14.27, 29356, 72.414, 6.467, 3.136, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "bob = Batter()\n",
    "print(list(jose))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob_data = np.array(list(bob)).reshape(1,-1)\n",
    "pred_class = pitching_model.predict(bob_data)\n",
    "pred_prob = pitching_model.predict_proba(bob_data)\n",
    "# ['left_field', 'center_field', 'right_field','min_wall_height','max_wall_height',\n",
    "                                    # 'attendance','temp','windspeed','season_era', 'daynight_day', 'daynight_night', 'precip_drizzle', 'precip_none', 'precip_rain', \n",
    "                                    # 'precip_snow', 'sky_cloudy', 'sky_dome', 'sky_overcast', 'sky_sunny', 'winddir_fromcf', 'winddir_fromlf', 'winddir_fromrf', 'winddir_ltor', \n",
    "                                    # 'winddir_rtol', 'winddir_tocf', 'winddir_tolf', 'winddir_torf', 'winddir_unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 0 0 0 0 0 0]]\n",
      "[array([[1.91315578e-04, 1.75529938e-02, 6.63668291e-02, 8.09934357e-01,\n",
      "        2.28810021e-02, 3.84205536e-03, 1.22857993e-02, 7.97109313e-04,\n",
      "        3.46737133e-05, 2.47956668e-05, 3.91959189e-04, 8.35930315e-03,\n",
      "        8.11778038e-04, 5.74990890e-05, 3.09591162e-04, 2.16819438e-02,\n",
      "        9.51838278e-04, 9.42886546e-05, 3.12501411e-02, 3.11182747e-04,\n",
      "        3.11280217e-04, 9.84340198e-04, 1.06834366e-05, 1.09768559e-05,\n",
      "        2.58925467e-04, 2.61371783e-04, 6.28165901e-06, 2.56838662e-05]]), array([[3.69829358e-01, 3.23964340e-01, 9.72784186e-02, 6.25816193e-02,\n",
      "        3.49610802e-02, 3.85918238e-02, 6.36890215e-02, 7.50601094e-03,\n",
      "        8.86831551e-04, 6.81525450e-04, 2.73384166e-06, 8.23928257e-07,\n",
      "        7.13562224e-08, 1.08781657e-07, 2.62329712e-05]]), array([[7.85999334e-01, 1.08562807e-01, 4.59237353e-02, 4.29812841e-02,\n",
      "        8.99256518e-03, 2.03155446e-03, 5.33486817e-03, 1.72039565e-04,\n",
      "        1.19593730e-06, 2.87433097e-07, 1.63153653e-08, 3.04972350e-07,\n",
      "        8.15167030e-09]]), array([[8.55795256e-01, 6.99086389e-02, 6.42987016e-02, 1.52179303e-03,\n",
      "        3.13295204e-03, 3.05998781e-03, 3.58647277e-04, 1.19388889e-06,\n",
      "        1.44716488e-06, 2.57985448e-05, 1.85919181e-03, 1.14178912e-05,\n",
      "        2.49740700e-05]]), array([[7.99787408e-01, 8.35366855e-02, 8.69382621e-02, 2.93719524e-02,\n",
      "        1.76630702e-04, 1.29241581e-04, 8.73062945e-06, 5.06832445e-05,\n",
      "        4.05937497e-07]]), array([[0.92739219, 0.02283786, 0.04456246, 0.00333503, 0.00187247]]), array([[9.62309484e-01, 9.64432826e-04, 2.77595974e-02, 7.77226874e-04,\n",
      "        8.18925867e-03]])]\n"
     ]
    }
   ],
   "source": [
    "print(pred_class)\n",
    "print(pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
